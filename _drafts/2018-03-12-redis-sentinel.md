---
layout: post
title: "Redis Sentinel"
date: "2018-03-12"
category:
  - it
  - tools
---

{% include image.html src="/assets/personal/2018-redis-sentinel.png" %}

## Общая информация
Redis Sentinel — это система, разработанная для помощи в управлении узлами Redis. Основные возможности:
- Мониторинг. Sentinel постоянно проверяет, что и мастер и слейвы работают, как ожидается. 
- Уведомление. Sentinel может сообщить системному администратору, другим компьютерным программам через API, что что-то не в порядке с одним из контролируемых экземпляров Redis.     
- Автоматический переключение. Если мастер работает не так, как ожидалось, Sentinel может запустить процесс восстановления после сбоя, когда slave становится master. 
- Поставщик конфигурации. Клиенты подключаются к Sentinels, чтобы запросить адрес текущего мастера Redis, ответственного за данную услугу. Если произойдет отказ, Sentinels сообщит о новом адресе.

  ### Запуск 
Запустить можно через ```redis-sentinel /path/to/sentinel.conf``` или ```redis-server /path/to/sentinel.conf --sentinel ```.

При запуске Sentinel обязательно использовать файл конфигурации, так как этот файл будет использоваться системой для сохранения текущего состояния, которое будет перезагружено в случае перезапуска.  Sentinel просто откажется запускаться, если файл конфигурации не указан или если путь к файлу конфигурации не доступен для записи.  Sentinel'ы постоянно общаются друг с другом.  

Пример конфигурации (http://download.redis.io/redis-stable/sentinel.conf).
```
port 26379 # Порт, на котором работает Sentinel 
sentinel monitor testmaster 127.0.0.1 6379 2  # sentinel monitor <master-group-name> <ip> <port> <quorum> 
```

Сервер Redis, который мы отслеживаем как группу . Здесь все довольно очевидно, но аргумент **quorum** - это количество Sentinel, которым необходимо договориться о том, что мастер недоступен, и, в случае необходимости, начать процедуру восстановления, если это возможно.  Однако кворум используется только для обнаружения отказа. Для того, чтобы действительно выполнить переход на другой ресурс, одному из Стражей нужно быть избранным лидером для перехода на другой ресурс и получить разрешение на продолжение. Это происходит только при голосовании большинства процессов Sentinel.

Так, например, если у вас есть 5 процессов Sentinel, а quorum для заданного мастера установлен в значение 2, это происходит следующим образом: 
- Если два Sentinel согласятся в то же время с тем, что мастер недоступен, один из двух попытается начать аварийное переключение.     
- Если, как минимум, доступно три Стража, переключение на другой ресурс будет санкционировано и фактически начнется.     
- На практике это означает, что во время сбоев Sentinel никогда не запускает аварийное переключение, если большинство процессов Sentinel не могут разговаривать (иначе не происходит сбой в разделе с меньшим числом участников).   

```  
sentinel down-after-milliseconds testmaster 5000 
# down-after-milliseconds - это время в миллисекундах, когда экземпляр не должен быть доступен (либо не отвечает на наши запросы, либо отвечает с ошибкой) для Sentinel, начинающего думать, что он не работает.     
sentinel failover-timeout testmaster 10000 
# Максимальное время, в течение которого происходит переход на другой ресурс     
sentinel parallel-syncs testmaster 1 
# устанавливает количество ведомых устройств, которые могут быть переконфигурированы, чтобы использовать новый мастер после перехода на другой ресурс одновременно. Чем меньше число, тем больше времени потребуется для завершения процесса восстановления после сбоя, однако, если подчиненные устройства настроены на обслуживание старых данных, вы можете не захотеть, чтобы все подчиненные устройства повторно синхронизировались с главным устройством одновременно. Хотя процесс репликации в основном не блокирует для ведомого, есть момент, когда он останавливается для загрузки объемных данных от ведущего. Вы можете убедиться, что только один подчиненный за раз недоступен, установив для этого параметра значение 1.     
sentinel notification-script <master-name> <script-path>
sentinel auth-pass <master-name> <password>
```

###   Команды Sentinel
 `PING` - эта команда просто возвращает PONG. 
`SENTINEL masters` - отображает список контролируемых мастеров и их состояние. 
`SENTINEL master <master name>` - показывает состояние и информацию указанного мастера.
 SENTINEL slaves <master name> Показывать список подчиненных устройств для этого ведущего и их состояние. 
SENTINEL sentinels <master name> Показывает список контрольных экземпляров для этого мастера и их состояние. 
SENTINEL get-master-addr-by-name <master name> Возвращает IP-адрес и номер порта мастера с этим именем. Если переход на другой ресурс выполняется или успешно завершен для этого ведущего устройства, он возвращает адрес и порт продвинутого ведомого.
 SENTINEL reset <pattern> Эта команда сбросит все мастера с соответствующим именем. Аргумент pattern является шаблоном стиля глобуса. Процесс сброса очищает любое предыдущее состояние в ведущем устройстве (включая выполняемый переход на другой ресурс) и удаляет все подчиненные устройства и сторожевой блок, которые уже обнаружены и связаны с главным. 
SENTINEL failover <master name> Принудительное переключение на резервный ресурс, как если бы мастер не был доступен и не запрашивал согласия у других Sentinels (однако новая версия конфигурации будет опубликована, чтобы другие Sentinels обновили свои конфигурации). 
SENTINEL ckquorum <master name> Проверьте, позволяет ли текущая конфигурация Sentinel достигать кворума, необходимого для перехода на другой ресурс ведущего, а большинству необходимо авторизовать переход на другой ресурс. Эта команда должна использоваться в системах мониторинга, чтобы проверить, нормально ли развертывается Sentinel.
 SENTINEL flushconfig Force Sentinel переписывает свою конфигурацию на диске, включая текущее состояние Sentinel. Обычно Sentinel перезаписывает конфигурацию каждый раз, когда что-то изменяется в ее состоянии (в контексте подмножества состояния, которое сохраняется на диске при перезапуске). Однако иногда возможно, что файл конфигурации потерян из-за ошибок в работе, сбоев диска, сценариев обновления пакета или менеджеров конфигурации. В таких случаях удобен способ заставить Sentinel переписать конфигурационный файл. Эта команда работает, даже если предыдущий файл конфигурации полностью отсутствует.  Реконфигурирование Sentinel во время выполнения Начиная с версии Redis версии 2.8.4, Sentinel предоставляет API для добавления, удаления или изменения конфигурации данного мастера. Обратите внимание, что если у вас несколько часовых, вы должны применить изменения ко всем экземплярам Redis Sentinel для правильной работы. Это означает, что изменение конфигурации отдельного Sentinel не автоматически распространяет изменения на других Sentinels в сети. SENTINEL MONITOR <name> <ip> <port> <quorum> quorum <quorum> Эта команда сообщает Sentinel начать мониторинг нового мастера с указанным именем, ip, портом и кворумом. Он идентичен директиве конфигурации сторожевого монитора в sentinel.conf файле sentinel.conf, с той разницей, что вы не можете использовать имя хоста в качестве ip , но вам нужно указать адрес IPv4 или IPv6. SENTINEL REMOVE <name> используется для удаления указанного ведущего: мастер больше не будет контролироваться и полностью будет удален из внутреннего состояния Sentinel, поэтому он больше не будет отображаться мастерами SENTINEL masters и т. SENTINEL masters SENTINEL SET <name> <option> <value> Команда SET очень похожа на команду CONFIG SET из Redis и используется для изменения параметров конфигурации конкретного ведущего устройства. Можно указать несколько пар option / value (или вообще ни одного). Все параметры конфигурации, которые могут быть сконфигурированы через sentinel.conf , также настраиваются с помощью команды SET.  Добавление или удаление Добавление нового Sentinel к вашему развертыванию является простым процессом из-за механизма автоматического обнаружения, реализованного Sentinel. Все, что вам нужно сделать, это запустить новый Sentinel, настроенный для мониторинга текущего активного мастера. В течение 10 секунд Sentinel получит список других Sentinels и набор подчиненных серверов, подключенных к мастеру. Удаление Sentinel немного сложнее: Sentinels никогда не забывают уже увиденные Sentinels , даже если они недоступны в течение длительного времени, так как мы не хотим динамически изменять большинство, необходимое для авторизации перехода на другой ресурс и создания новой конфигурации номер. Поэтому, чтобы удалить Sentinel, в отсутствие сетевых разделов необходимо выполнить следующие шаги: Остановите Sentinel процесс Sentinel, который вы хотите удалить. Отправьте команду SENTINEL RESET * во все остальные экземпляры Sentinel (вместо * вы можете использовать точное имя мастера, если хотите сбросить только один мастер). Один за другим, ожидая по крайней мере 30 секунд между инстанциями. Убедитесь, что все Дозорные согласны с количеством активных Часов, проверяя вывод SENTINEL MASTER mastername каждого Sentinel.  Удаление старого основного или недостижимого подчиненных устройств Стражи никогда не забывают о рабах данного мастера, даже если они недостижимы в течение долгого времени. Это полезно, потому что Sentinels должны иметь возможность правильно перенастроить возвращаемое подчиненное устройство после сетевого раздела или события сбоя. Более того, после переключения на резервный ресурс сбойный главный мастер фактически добавляется в качестве подчиненного устройства нового мастера, таким образом он будет перенастроен для репликации с новым мастером, как только он будет доступен снова. Однако иногда вы хотите удалить ведомого (который может быть старым мастером) навсегда из списка подчиненных, контролируемых Sentinels. In order to do this, you need to send a SENTINEL RESET mastername command to all the Sentinels: they'll refresh the list of slaves within the next 10 seconds, only adding the ones listed as correctly replicating from the current master INFO output.  Сообщение Sentinel Клиент может использовать Sentinel, так как он был совместимым с Redis Pub / Sub сервером (но вы не можете использовать PUBLISH ) для того, чтобы ПОДПИСАТЬСЯ или ПЛАНИРОВАТЬ на каналы и получать уведомления о конкретных событиях. Имя канала совпадает с именем события. Например, канал с именем +sdown получит все уведомления, связанные с экземплярами, входящими в SDOWN (SDOWN означает, что экземпляр больше недоступен с точки зрения запрашиваемого Sentinel). Чтобы получить все сообщения, просто подпишитесь, PSUBSCRIBE * . Ниже приведен список каналов и форматов сообщений, которые вы можете получить с помощью этого API. Первое слово - это название канала / события, остальное - формат данных. <instance details> -- <instance-type> <name> <ip> <port> @ <master-name> <master-ip> <master-port> +reset-master <instance details> -- The master was reset. +slave <instance details> -- A new slave was detected and attached. +failover-state-reconf-slaves <instance details> -- Failover state changed to reconf-slaves state. +failover-detected <instance details> -- A failover started by another Sentinel or any other external entity was detected (An attached slave turned into a master). +slave-reconf-sent <instance details> -- The leader sentinel sent the SLAVEOF command to this instance in order to reconfigure it for the new slave. +slave-reconf-inprog <instance details> -- The slave being reconfigured showed to be a slave of the new master ip:port pair, but the synchronization process is not yet complete. +slave-reconf-done <instance details> -- The slave is now synchronized with the new master. -dup-sentinel <instance details> -- One or more sentinels for the specified master were removed as duplicated (this happens for instance when a Sentinel instance is restarted). +sentinel <instance details> -- A new sentinel for this master was detected and attached. +sdown <instance details> -- The specified instance is now in Subjectively Down state. -sdown <instance details> -- The specified instance is no longer in Subjectively Down state. +odown <instance details> -- The specified instance is now in Objectively Down state. -odown <instance details> -- The specified instance is no longer in Objectively Down state. +new-epoch <instance details> -- The current epoch was updated. +try-failover <instance details> -- New failover in progress, waiting to be elected by the majority. +elected-leader <instance details> -- Won the election for the specified epoch, can do the failover. +failover-state-select-slave <instance details> -- New failover state is select-slave: we are trying to find a suitable slave for promotion. no-good-slave <instance details> -- There is no good slave to promote. Currently we'll try after some time, but probably this will change and the state machine will abort the failover at all in this case. selected-slave <instance details> -- We found the specified good slave to promote. failover-state-send-slaveof-noone <instance details> -- We are trying to reconfigure the promoted slave as master, waiting for it to switch. failover-end-for-timeout <instance details> -- The failover terminated for timeout, slaves will eventually be configured to replicate with the new master anyway. failover-end <instance details> -- The failover terminated with success. All the slaves appears to be reconfigured to replicate with the new master. switch-master <master name> <oldip> <oldport> <newip> <newport> -- The master new IP and address is the specified one after a configuration change. This is the message most external users are interested in. +tilt -- Tilt mode entered. -tilt -- Tilt mode exited.  Как выбирается Redis экземпляры имеют параметр конфигурации с именем slave-priority. Эта информация подвергаются ведомым экземплярами Redis в их INFO выходе, и Страж использует его для того , чтобы выбрать раб среди тех , которые могут быть использованы для того , чтобы отказоустойчивых мастеров: Если приоритет ведомое установлен в 0, то ведомый никогда не назначен мастером. Ведомые с более низким номером приоритета предпочитают Sentinel. Например, если есть ведомый S1, в том же самом центре обработки данных текущего хозяина, а другой ведомый S2 в другом центре обработки данных, можно установить S1 с приоритетом 10 и S2 с приоритетом 100, так что если мастер терпит неудачу и оба S1 и S2 доступны, будет предпочтительнее S1. Для получения более подробной информации о способе выбирается рабы, пожалуйста , проверьте выбор ведомого и приоритет раздел этой документации.  SDOWN and ODOWN failure state Redis Sentinel has two different concepts of being down, one is called a Subjectively Down condition (SDOWN) and is a down condition that is local to a given Sentinel instance. Another is called Objectively Down condition (ODOWN) and is reached when enough Sentinels (at least the number configured as the quorum parameter of the monitored master) have an SDOWN condition, and get feedback from other Sentinels using the SENTINEL is-master-down-by-addr command. SDOWN и ODOWN состояние отказа Redis Страж имеет два различных понятия бытия вниз , один называется Субъективно вниз условие (SDOWN) и вниз условие , которое является локальным для данного экземпляра Sentinel. Другой называются Объективно вниз условием (ODOWN) и достигаются при достаточно Sentinels (по крайней мере, количество сконфигурирована как quorumпараметр контролируемого мастера) есть условие SDOWN, и получить обратную связь от других Стражей , используя SENTINEL is-master-down-by-addrкоманду. С точки зрения Стражем состояния SDOWN достигаются тогда , когда он не получает правильный ответ на PING запросы на количество секунд , указанных в конфигурации в качестве is-master-down-after-millisecondsпараметра. Приемлемый ответ на PING является одним из следующих: PING ответил + Pong. PING ответил -LOADING ошибки. PING ответил -MASTERDOWN ошибки. Обратите внимание, что SDOWN требует, чтобы не приемлемый ответ не будет получен в течение всего интервала сконфигурированного, так, например, если интервал составляет 30000 миллисекунд (30 секунд), и мы получаем приемлемый пинг ответ каждые 29 секунд, экземпляр считается работать. SDOWN не достаточно, чтобы вызвать переход на другой ресурс: это означает только один Страж считает экземпляр Redis не доступен. Для того, чтобы вызвать переход на другой ресурс, состояние ODOWN должно быть достигнуто. Для того, чтобы перейти от SDOWN к ODOWN не используется сильный алгоритм консенсуса, но только форма сплетен: если данный Страж получает отчеты о том , что мастер не работает с достаточно Стражей в заданном временном интервале , то SDOWN повышен до ODOWN. Если это признают позже отсутствует, флаг сброшен.  Sentinels and Slaves автоматическое обнаружение Часовые оставаться на связи с другими Стражами, чтобы обоюдно проверить наличие друг друга и обмениваться сообщениями. Однако вам не нужно, чтобы настроить список другой Стражи адресов в каждом случае часового запускается как Страж использует экземпляры Redis Паб возможности / Sub для того, чтобы обнаружить другие Страж, которые следят за одни и те же мастерами и раб. Эта функция реализуется путем отправки привет сообщений в канал имени __sentinel__:hello. Точно так же вам не нужно настроить, что список рабов, прикрепленных к мастеру, так как Сентинел будет автоматически открыть этот список Redis-опроса. Каждый Сентинел публикует сообщение каждому мониторинг ведущий и ведомый Pub / Sub канала __sentinel__:hello, каждые две секунды, объявив о своем присутствии с IP, порт, RunID. Каждый Сентинели подписан на Pub / Sub канал __sentinel__:helloкаждые ведущего и ведомого, ищет неизвестные часовые. Когда новые Часовые обнаруживаются, они добавляются в качестве часовых этого мастера. Привет сообщение также включает в себя полную текущую конфигурацию мастера. Если принимающий Дозорный имеет конфигурацию для данного мастера, который старше, чем один получил, он обновляет к новой конфигурации немедленно. Перед добавлением нового стража к мастеру Стража всегда проверяет, есть ли уже сторожевого с той же RunID или тот же адрес (адрес и порт пара). В этом случае все совпадающие Часовые удаляются, а новый добавлен.  Slave selection and priority When a Sentinel instance is ready to perform a failover, since the master is in ODOWN state and the Sentinel received the authorization to failover from the majority of the Sentinel instances known, a suitable slave needs to be selected. The slave selection process evaluates the following information about slaves: Disconnection time from the master. Slave priority. Replication offset processed. Run ID. Раб, который находится отключиться от мастера более чем в десять раз настроенного мастера тайм-ауте (down-after-milliseconds опции), плюс время мастер также не доступен с точки зрения Стражи делает переход на другой ресурс, считается не подходит для перехода на другой ресурс и пропускается. В более строгих условиях, раб которого находится INFO выход предполагает быть отсоединен от ведущего в течение более чем:  (down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state Считается ненадежным и не учитывается полностью. Выбор ведомого учитывает только рабов, которые прошли выше проверку, и сортирует их на основе вышеуказанных критериев, в следующем порядке. Рабы сортируются по slave-priorityв соответствии с настройками в redis.confфайле экземпляра Redis. Будет предпочтительнее более низкий приоритет. Если приоритет одно и то же, репликация обрабатываемого сдвига ведомых проверяются, а ведомый, который получил больше данных от ведущего устройства выбрана. Если несколько подчиненных устройства имеют одинаковый приоритет и обрабатываются одни и те же данные от мастера, дальнейшая проверка выполняется, выбор ведомого с меньшим лексикографическомом выполнения ID. Имея более низкую перспективу ID не является реальным преимуществом для раба, но полезно для того, чтобы сделать процесс выбора ведомого более детерминированного, вместо того, чтобы прибегать, чтобы выбрать случайную рабыню Redis masters (that may be turned into slaves after a failover), and slaves, all must be configured with a slave-priority if there are machines to be strongly preferred. Otherwise all the instances can run with the default run ID (which is the suggested setup, since it is far more interesting to select the slave by replication offset). A Redis instance can be configured with a special slave-priority of zero in order to be never selected by Sentinels as the new master. However a slave configured in this way will still be reconfigured by Sentinels in order to replicate with the new master after a failover, the only difference is that it will never become a master itself.  QUORUM The previous sections showed that every master monitored by Sentinel is associated to a configured quorum. It specifies the number of Sentinel processes that need to agree about the unreachability or error condition of the master in order to trigger a failover. However, after the failover is triggered, in order for the failover to actually be performed, at least a majority of Sentinels must authorize the Sentinel to failover. Sentinel never performs a failover in the partition where a minority of Sentinels exist. Let's try to make things a bit more clear: Quorum: the number of Sentinel processes that need to detect an error condition in order for a master to be flagged as ODOWN. The failover is triggered by the ODOWN state. Once the failover is triggered, the Sentinel trying to failover is required to ask for authorization to a majority of Sentinels (or more than the majority if the quorum is set to a number greater than the majority). The difference may seem subtle but is actually quite simple to understand and use. For example if you have 5 Sentinel instances, and the quorum is set to 2, a failover will be triggered as soon as 2 Sentinels believe that the master is not reachable, however one of the two Sentinels will be able to failover only if it gets authorization at least from 3 Sentinels. If instead the quorum is configured to 5, all the Sentinels must agree about the master error condition, and the authorization from all Sentinels is required in order to failover. This means that the quorum can be used to tune Sentinel in two ways: If a the quorum is set to a value smaller than the majority of Sentinels we deploy, we are basically making Sentinel more sensible to master failures, triggering a failover as soon as even just a minority of Sentinels is no longer able to talk with the master. If a quorum is set to a value greater than the majority of Sentinels, we are making Sentinel able to failover only when there are a very large number (larger than majority) of well connected Sentinels which agree about the master being down. кворум В предыдущих разделах показано , что каждый мастер контролируется Сентинеля связан с настроенным кворума . Он определяет количество Стражей процессов , которые должны договориться о недостижимости или ошибке состоянии мастера для того , чтобы вызвать переход на другой ресурс. Однако, после того , как отказоустойчивый срабатывают, для того , чтобы переключения на самом деле выполняться, по крайней мере , большинство из Стражей должны разрешать Страж отказоустойчивого . Страж никогда не выполняет переход на другой ресурс в раздел , где меньшинство Стражей существует. Давайте попробуем сделать вещи немного более ясно: Кворум: количество Стражей процессов , которые необходимо обнаружить состояние ошибки для того , чтобы мастер быть помечен как ODOWN . Отказоустойчивого запускается в ODOWN состоянии. После того, как отказоустойчивый срабатывает, Страж пытается отказоустойчивых требуется запросить разрешение для большинства Стражей (или больше, чем большинство, если кворум устанавливается на значение, которое больше, чем большинство). Разница может показаться тонкой, но на самом деле довольно прост для понимания и использования. Например, если у вас есть 5 экземпляров Sentinel, и кворум устанавливается на 2, отказоустойчивый будет запускаться, как только 2 Часовые считают, что мастер не доступен, однако один из двух Стражей будет иметь возможность отказоустойчивого только если он получает авторизации по меньшей мере, от 3 Стражей. Если вместо того, чтобы кворум настроен на 5, все Часовые должны договориться о состоянии мастер ошибки, и разрешение от всех Стражей требуется для того, чтобы переход на другой ресурс. Это означает, что кворум может быть использован для настройки Стражи два способов: Если кворум устанавливаются на меньшее значение, чем большинство Стражей мы направляем, мы в основном делаем Стражу более разумными освоить сбои, вызывая переход на другой ресурс, как только даже просто меньшинство Стражей уже не в состоянии говорить с мастером , Если кворум установлен на значение больше, чем большинство Стражей, мы делаем Сентинели возможность отказоустойчивых только тогда, когда есть очень большое количество (больше, чем большинство) хорошо подсоединенных Стражи, согласующиеся о мастер будучи вниз.   Configuration epochs Sentinels require to get authorizations from a majority in order to start a failover for a few important reasons: When a Sentinel is authorized, it gets a unique configuration epoch for the master it is failing over. This is a number that will be used to version the new configuration after the failover is completed. Because a majority agreed that a given version was assigned to a given Sentinel, no other Sentinel will be able to use it. This means that every configuration of every failover is versioned with a unique version. We'll see why this is so important. Moreover Sentinels have a rule: if a Sentinel voted another Sentinel for the failover of a given master, it will wait some time to try to failover the same master again. This delay is the failover-timeout you can configure in sentinel.conf. This means that Sentinels will not try to failover the same master at the same time, the first to ask to be authorized will try, if it fails another will try after some time, and so forth. Redis Sentinel guarantees the liveness property that if a majority of Sentinels are able to talk, eventually one will be authorized to failover if the master is down. Redis Sentinel also guarantees the safety property that every Sentinel will failover the same master using a different configuration epoch. эпохи конфигурации Часовые требуют, чтобы получить разрешение от большинства, чтобы начать переход на другой ресурс на несколько важных причины: Когда Страж авторизован, он получает уникальную конфигурацию эпоху для мастера он неисправный над. Это число , которое будет использоваться для версии новой конфигурации после перехода на другой ресурс будет завершена. Поскольку большинство согласились , что данная версия была передана данной Стража, никакой другой Страж не сможет его использовать. Это означает , что каждая конфигурация каждого перехода на другой ресурс версирован с уникальной версией. Мы увидим , почему это так важно. Кроме того Часовые есть правило: если Страж проголосовал другую Стражу для перехода на другой ресурс данного мастера, он будет ждать некоторое время , чтобы попытаться отказоустойчивыми тот же мастер еще раз. Эта задержка является failover-timeoutвы можете настроить в sentinel.conf. Это означает , что Часовые не будет пытаться отказоустойчивых тот же мастер , в то же время, первый попросить быть авторизован будет пытаться, если он не будет пытаться другой через какое - то время, и так далее. Redis Страж гарантирует живучести свойством , что если большинство Стражей в состоянии говорить, в конце концов , один будет уполномочен отказоустойчивых если хозяин вниз. Redis Сентинел также гарантирует безопасность имущества , что каждый Страж будет отказоустойчивых один и тот же мастер с использованием другой конфигурации эпохи .   Configuration propagation Once a Sentinel is able to failover a master successfully, it will start to broadcast the new configuration so that the other Sentinels will update their information about a given master. For a failover to be considered successful, it requires that the Sentinel was able to send the SLAVEOF NO ONE command to the selected slave, and that the switch to master was later observed in the INFO output of the master. At this point, even if the reconfiguration of the slaves is in progress, the failover is considered to be successful, and all the Sentinels are required to start reporting the new configuration. The way a new configuration is propagated is the reason why we need that every Sentinel failover is authorized with a different version number (configuration epoch). Every Sentinel continuously broadcast its version of the configuration of a master using Redis Pub/Sub messages, both in the master and all the slaves. At the same time all the Sentinels wait for messages to see what is the configuration advertised by the other Sentinels. Configurations are broadcast in the __sentinel__:hello Pub/Sub channel. Because every configuration has a different version number, the greater version always wins over smaller versions. So for example the configuration for the master mymaster start with all the Sentinels believing the master is at 192.168.1.50:6379. This configuration has version 1. After some time a Sentinel is authorized to failover with version 2. If the failover is successful, it will start to broadcast a new configuration, let's say 192.168.1.50:9000, with version 2. All the other instances will see this configuration and will update their configuration accordingly, since the new configuration has a greater version. This means that Sentinel guarantees a second liveness property: a set of Sentinels that are able to communicate will all converge to the same configuration with the higher version number. Basically if the net is partitioned, every partition will converge to the higher local configuration. In the special case of no partitions, there is a single partition and every Sentinel will agree about the configuration. распространение конфигурации После того, как Страж способен отказоустойчивыми мастер успешно, он начнет транслировать новую конфигурацию, так что другие Часовые будут обновлять информацию о данных мастерах. Для перехода на другой ресурс будет считаться успешным, он требует, чтобы Сентинел был в состоянии послать SLAVEOF NO ONEкоманду к выбранному ведомым, и что переход на мастер был впоследствии обнаружен в INFO выход мастера. На данный момент, даже если реконфигурация рабов продолжаются, отказоустойчивый считаются успешными, и все Часовые должны начать представлять новую конфигурацию. То, как новая конфигурация распространяется причина, почему нам нужно, чтобы каждый Страж отказоустойчивого уполномочен с другим номером версии (конфигурация эпохи). Каждый Сентинел непрерывно транслировать свою версию конфигурации мастера с помощью Redis Pub / Sub сообщения, как в ведущих и всех рабах. В то же время все Часовые ждать сообщения, чтобы увидеть, что конфигурация рекламируемой других Стражами. Конфигурации транслируются в __sentinel__:helloPub / Sub канала. Поскольку каждая конфигурация имеет другой номер версии, тем больше версия всегда побеждает более мелкие версии. Так, например , конфигурация для мастера mymasterзапуска со всеми Часовые полагая , мастер на 192.168.1.50:6379. Эта конфигурация имеет версию 1. После того, как некоторое время Страж уполномочен отказоустойчивым с версией 2. Если отказоустойчивое успешно, он начнет транслировать новую конфигурацию, скажем 192.168.1.50:9000 с версией 2. Все остальные экземпляры увижу эту конфигурацию и обновит свою конфигурацию соответственно, так как новая конфигурация имеет большую версию. Это означает, что Страж гарантирует второе живучести свойства: множество Стражей, которые способны общаться будут все сходятся к одной и той же конфигурации с более высоким номером версии. В принципе, если сеть разделена, каждый раздел будет сходиться к более высокой локальной конфигурации. В частном случае каких-либо перегородок, существует один раздел, и каждый Дозорный договорятся о конфигурации.   Consistency under partitions Redis Sentinel configurations are eventually consistent, so every partition will converge to the higher configuration available. However in a real-world system using Sentinel there are three different players: Redis instances. Sentinel instances. Clients. In order to define the behavior of the system we have to consider all three. The following is a simple network where there are 3 nodes, each running a Redis instance, and a Sentinel instance In this system the original state was that Redis 3 was the master, while Redis 1 and 2 were slaves. A partition occurred isolating the old master. Sentinels 1 and 2 started a failover promoting Sentinel 1 as the new master. The Sentinel properties guarantee that Sentinel 1 and 2 now have the new configuration for the master. However Sentinel 3 has still the old configuration since it lives in a different partition. We know that Sentinel 3 will get its configuration updated when the network partition will heal, however what happens during the partition if there are clients partitioned with the old master? Clients will be still able to write to Redis 3, the old master. When the partition will rejoin, Redis 3 will be turned into a slave of Redis 1, and all the data written during the partition will be lost. Depending on your configuration you may want or not that this scenario happens: If you are using Redis as a cache, it could be handy that Client B is still able to write to the old master, even if its data will be lost. If you are using Redis as a store, this is not good and you need to configure the system in order to partially prevent this problem. Since Redis is asynchronously replicated, there is no way to totally prevent data loss in this scenario, however you can bound the divergence between Redis 3 and Redis 1 using the following Redis configuration option: min-slaves-to-write 1 min-slaves-max-lag 10 With the above configuration (please see the self-commented redis.conf example in the Redis distribution for more information) a Redis instance, when acting as a master, will stop accepting writes if it can't write to at least 1 slave. Since replication is asynchronous not being able to write actually means that the slave is either disconnected, or is not sending us asynchronous acknowledges for more than the specified max-lag number of seconds. Using this configuration the Redis 3 in the above example will become unavailable after 10 seconds. When the partition heals, the Sentinel 3 configuration will converge to the new one, and Client B will be able to fetch a valid configuration and continue. In general Redis + Sentinel as a whole are a an eventually consistent system where the merge function is last failover wins, and the data from old masters are discarded to replicate the data of the current master, so there is always a window for losing acknowledged writes. This is due to Redis asynchronous replication and the discarding nature of the "virtual" merge function of the system. Note that this is not a limitation of Sentinel itself, and if you orchestrate the failover with a strongly consistent replicated state machine, the same properties will still apply. There are only two ways to avoid losing acknowledged writes: Use synchronous replication (and a proper consensus algorithm to run a replicated state machine). Use an eventually consistent system where different versions of the same object can be merged. Redis currently is not able to use any of the above systems, and is currently outside the development goals. However there are proxies implementing solution "2" on top of Redis stores such as SoundCloud Roshi, or Netflix Dynomite. Sentinel persistent state Sentinel state is persisted in the sentinel configuration file. For example every time a new configuration is received, or created (leader Sentinels), for a master, the configuration is persisted on disk together with the configuration epoch. This means that it is safe to stop and restart Sentinel processes. Консистенция под перегородками Конфигурации Redis дозорных в конечном счете, последовательные, так что каждый раздел будет сходиться к более высокой конфигурации доступны. Однако в реальном мире системы с использованием Sentinel, есть три разных игрока: Redis экземпляров. Дозорные экземпляров. Клиенты. Для того, чтобы определить поведение системы, мы должны рассмотреть все три. Ниже приведен простая сеть, в которой есть 3 узлов, каждый из которых работает экземпляр Redis, и Сентинел экземпляр:   +-------------+ | Sentinel 1 |----- Client A | Redis 1 (M) | +-------------+ | | +-------------+ | +------------+ | Sentinel 2 |-----+-- // ----| Sentinel 3 |----- Client B | Redis 2 (S) | | Redis 3 (M)| +-------------+ +------------+ В этой системе первоначальное состояние было то, что Redis 3 был хозяином, в то время как Redis 1 и 2 были рабами. Перегородка произошло выделение старого мастера. Часовые 1 и 2 начали отказоустойчивой Дозорный 1 способствуя как новый хозяин. Свойства Дозорные гарантирует, что Сентинел 1 и 2 теперь имеют новую конфигурацию для мастера. Однако Страж 3 имеет еще старую конфигурацию, так как он живет в другом разделе. Мы знаем, что Страж 3 получит его конфигурация обновляется, когда сеть раздел будет заживать, однако то, что происходит во время раздела, если имеются клиенты распределяли со старым мастером? Клиенты будут все еще в состоянии написать Redis 3, старый мастер. Когда раздел будет воссоединиться, Redis 3 будет превращен в раба Redis 1, и все данные, записанные во время раздела будут потеряны. В зависимости от конфигурации вы можете или не то, что этот сценарий происходит: Если вы используете Redis в качестве кэш-памяти, это может быть удобно, что клиент B все еще в состоянии написать к старому мастеру, даже если его данные будут потеряны. Если вы используете Redis в магазине, это не хорошо, и вам нужно настроить систему для того, чтобы частично предотвратить эту проблему. Поскольку Redis асинхронно реплицировать, нет никакого способа, чтобы полностью предотвратить потерю данных в этом случае, однако, вы можете связаны расхождения между Redis 3 и Redis 1, используя следующие опции конфигурации Redis:  min-slaves-to-write 1 min-slaves-max-lag 10 При вышеуказанной конфигурации (см самоконтрящимся комментировал redis.confпример в распределении Redis для получения дополнительной информации) экземпляр Redis, действуя в качестве ведущего, перестанет принимать операции записи , если он не может написать по крайней мере 1 раб. Поскольку репликация асинхронная не в состоянии написать на самом деле означает , что ведомое либо отключен, либо не посылает нам асинхронным признает более чем указанное max-lagколичество секунд. С помощью этой конфигурации Redis 3 в приведенном выше примере будет недоступно через 10 секунд. Когда разделительные заживает, конфигурация Sentinel 3 будет сходиться к новому, и клиент B будет иметь возможность принести действительную конфигурацию и продолжить. В общем Redis + Страже в целом являются в конечном счете , последовательная систему , где функция слияния последних отказоустойчивые побед , и данные из старых мастеров, отбрасываются реплицировать данные текущего мастера, так что всегда есть окно для потери признаваемых пишет , Это связано с Redis асинхронной репликации и отбрасывание природы «виртуальной» сливаться функции системы. Обратите внимание , что это не является ограничением самого Стража, и если вы организовать переход на другой ресурс с сильно последовательной реплицированного государственной машины, те же свойства , по - прежнему применяются. Есть только два пути , чтобы избежать потерь признаваемых пишет: Используйте синхронную репликацию (и правильный алгоритм консенсуса запустить реплицированную государственную машину). Используйте в конечном счете, последовательную систему, в которой могут быть объединены различные версии одного и того же объекта. Redis в настоящее время не в состоянии использовать любого из вышеуказанных систем, и в настоящее время за пределами целей развития. Однако есть прокси - серверы , реализующие решение «2» в верхней части Redis магазинов , таких как SoundCloud Роши , или Netflix Dynomite . Дозорного постоянное состояние Дозорное состояние сохраняется в файле конфигурации дозорной. Например, каждый раз, когда новая конфигурация получена или создана (лидер Стражи), для мастера, конфигурация сохраняется на диск вместе с эпохой конфигурации. Это означает, что это безопасно, чтобы остановить и перезапустить Sentinel процессы.   TILT mode Redis Sentinel is heavily dependent on the computer time: for instance in order to understand if an instance is available it remembers the time of the latest successful reply to the PING command, and compares it with the current time to understand how old it is. However if the computer time changes in an unexpected way, or if the computer is very busy, or the process blocked for some reason, Sentinel may start to behave in an unexpected way. The TILT mode is a special "protection" mode that a Sentinel can enter when something odd is detected that can lower the reliability of the system. The Sentinel timer interrupt is normally called 10 times per second, so we expect that more or less 100 milliseconds will elapse between two calls to the timer interrupt. What a Sentinel does is to register the previous time the timer interrupt was called, and compare it with the current call: if the time difference is negative or unexpectedly big (2 seconds or more) the TILT mode is entered (or if it was already entered the exit from the TILT mode postponed). When in TILT mode the Sentinel will continue to monitor everything, but: It stops acting at all. It starts to reply negatively to SENTINEL is-master-down-by-addr requests as the ability to detect a failure is no longer trusted. If everything appears to be normal for 30 second, the TILT mode is exited. Note that in some way TILT mode could be replaced using the monotonic clock API that many kernels offer. However it is not still clear if this is a good solution since the current system avoids issues in case the process is just suspended or not executed by the scheduler for a long time. режим TILT Redis Сентинел в значительной степени зависит от времени компьютера: например, для того, чтобы понять, если экземпляр доступен он запоминает время последнего успешного ответа на команду PING, и сравнивает его с текущим временем, чтобы понять, сколько ему лет. Однако, если время компьютера изменяется неожиданным образом, или если компьютер очень занят, или процесс блокируется каким-то причинам, Страж может начать вести себя неожиданным образом. Режим TILT специальный режим «защита», что Страж может войти, когда что-то странное обнаруживается, что может привести к снижению надежности системы. Прерывание таймера Сентинел обычно называют 10 раз в секунду, поэтому мы ожидаем, что более или менее 100 миллисекунд будут проходить между двумя вызовами прерывания таймера. Какой Страж делает это зарегистрировать предыдущий раз, когда прерывание таймера был вызван, и сравнить его с текущим вызовом: если разница во времени отрицательна или неожиданно большой (2 секунды или более) режим TILT вводится (или, если это уже было вошел выход из режима TILT отложенного). При работе в режиме НАКЛОНА Стража будет продолжать контролировать все, но: Он перестает действовать на всех. Он начинает отвечать отрицательно на SENTINEL is-master-down-by-addrпросьбы как способность обнаружить неисправность больше не доверяли. Если все выглядит нормально в течение 30 сек, режим TILT завершается. Обратите внимание, что в каком-то режиме НАКЛОНА образом можно заменить с помощью монотонных часов API, которые предлагают много ядер. Однако это все еще не ясно, если это хорошее решение, так как существующая система позволяет избежать проблем в случае, когда процесс только приостановлен или не выполняется планировщиком в течение длительного времени.
